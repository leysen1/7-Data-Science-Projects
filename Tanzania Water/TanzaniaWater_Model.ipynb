{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = '/Users/charlotteleysen/Google Drive/*PROJECTS/IE/Term 2/Machine Leaning 2/Tanzania Water Assignment/outputs/'\n",
    "df = pd.read_csv(f_path + 'train_clean.csv')\n",
    "df_test = pd.read_csv(f_path + 'test_clean.csv')\n",
    "f_path = '/Users/charlotteleysen/Google Drive/*PROJECTS/IE/Term 2/Machine Leaning 2/Tanzania Water Assignment/data/'\n",
    "df_test_origin = pd.read_csv(f_path + 'test_set.csv')\n",
    "del df['Unnamed: 0']\n",
    "df_test = df_test.rename(columns={'Unnamed: 0': 'id'})\n",
    "\n",
    "df_test_origin = df_test_origin.sort_values('id', ascending=True)\n",
    "a = list(df_test_origin.index)\n",
    "df_test['order'] = a\n",
    "df_test = df_test.sort_values('order', ascending=True)\n",
    "\n",
    "df_all = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing  Data for Modelling by converting object variables to categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(df_all.select_dtypes(['object']).columns)\n",
    "df_all[names] = df_all[names].apply(lambda x: x.astype('category'))\n",
    "df_test[names] = df_test[names].apply(lambda x: x.astype('category'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing categories to numeric codes\n",
    "Every variable should be numeric - the model works better with numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[names] = df_all[names].apply(lambda x: x.cat.codes)\n",
    "df_test[names] = df_test[names].apply(lambda x: x.cat.codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f3a1d584a6a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_all' is not defined"
     ]
    }
   ],
   "source": [
    "df_all.dtypes\n",
    "df.status_group.head(30)\n",
    "df_all.status_group.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "Status group has been changed to the following numeric codes:\n",
    "non functional = 2, functional = 0, needs repair = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-23991e47d4e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m.75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status_group'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_all' is not defined"
     ]
    }
   ],
   "source": [
    "df_all['is_train'] = np.random.uniform(0, 1, len(df_all)) <= .75\n",
    "train, test = df_all[df_all['is_train']], df_all[df_all['is_train'] == False]\n",
    "\n",
    "features = df_all.drop(['status_group', 'is_train'], axis=1).columns\n",
    "features\n",
    "target = train['status_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    n_estimators=25,\n",
    "    n_jobs=15,\n",
    "    random_state=0,\n",
    "    min_samples_split=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_depth=25)\n",
    "clf.fit(train[features], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "clf.predict(test[features])\n",
    "clf.predict_proba(test[features])[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores\n",
    "clf.score(test[features], test.status_group)\n",
    "confusion_matrix(test.status_group, clf.predict(test[features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Hyperparameter Optimising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=20, stop=200, num=20)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=21)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 5, 8, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "clf2 = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation,\n",
    "# search across 100 different combinations, and use all available cores\n",
    "clf2_random = RandomizedSearchCV(\n",
    "    estimator=clf2,\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=100,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the random search model\n",
    "\n",
    "Initial model parameters result: {'n_estimators': 143, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': False}\n",
    "\n",
    "\n",
    "New model result: {'n_estimators': 181, 'min_samples_split': 10,'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 95, 'bootstrap': False}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf2_random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-85dc6e382fbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf2_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclf2_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf2_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf2_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf2_random' is not defined"
     ]
    }
   ],
   "source": [
    "clf2_random.fit(train[features], target)\n",
    "clf2_random.best_params_\n",
    "clf2_random.score(test[features], test.status_group)\n",
    "\n",
    "confusion_matrix(test.status_group, clf2_random.predict(test[features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgmodel = xgb.XGBClassifier(\n",
    "    max_depth=10,\n",
    "    objective='binary:logistic',\n",
    "    subsample=1,\n",
    "    colsample_bytree=0.8,\n",
    "    learning_rate=0.4,\n",
    "    min_child_weight=1.7)\n",
    "xgmodel.fit(train[features], target)\n",
    "xgmodel.score(test[features], test.status_group)\n",
    "\n",
    "xgmodel.predict(test[features])\n",
    "xgmodel.predict_proba(test[features])\n",
    "\n",
    "xgmodel.score(test[features], test.status_group)\n",
    "confusion_matrix(test.status_group, xgmodel.predict(test[features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Hyperparameter Optimising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=20, stop=200, num=20)]\n",
    "colsample_bytree = [float(x) for x in np.linspace(start=0.5, stop=1, num=5)]\n",
    "subsample = [float(x) for x in np.linspace(start=0.5, stop=1, num=5)]\n",
    "gamma = [float(x) for x in np.linspace(start=0, stop=10, num=16)]\n",
    "learning_rate = [float(x) for x in np.linspace(start=0, stop=0.3, num=4)]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'colsample_bytree': colsample_bytree,\n",
    "               'subsample': subsample,\n",
    "               'gamma': gamma,\n",
    "               'learning_rate': learning_rate}\n",
    "\n",
    "xgmodel2 = xgb.XGBClassifier()\n",
    "xgmodel_random = RandomizedSearchCV(\n",
    "    estimator=xgmodel2,\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=100,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the random search model\n",
    "Initial model parameters result: {'subsample': 0.75, 'n_estimators': 171, 'learning_rate': 0.3, 'gamma': 0.6666666666666666, 'colsample_bytree': 1.0}\n",
    "\n",
    "New model results : {'subsample': 0.5, 'n_estimators': 181, 'learning_rate': 0.3, 'gamma': 2.0, 'colsample_bytree': 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgmodel_random.fit(train[features], target)\n",
    "xgmodel_random.best_params_\n",
    "xgmodel_random.predict(test[features])\n",
    "confusion_matrix(test.status_group, xgmodel_random.predict(test[features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2_random.predict_proba(test[features])\n",
    "xgmodel_random.predict_proba(test[features])\n",
    "\n",
    "pred1 = clf2_random.predict_proba(test[features])\n",
    "pred2 = xgmodel_random.predict_proba(test[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight the models 80% random forest, 20%XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_comb = pd.DataFrame(0.8 * pred1 + 0.2 * pred2)\n",
    "preds_comb.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test.status_group, preds_comb.idxmax(axis=1))\n",
    "confusion_matrix(test.status_group, xgmodel_random.predict(test[features]))\n",
    "confusion_matrix(test.status_group, clf2_random.predict(test[features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain on whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_final = RandomForestClassifier(\n",
    "    n_estimators=181,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    max_depth=95,\n",
    "    bootstrap=False)\n",
    "clf_final.fit(df_all[features], df_all['status_group'])\n",
    "\n",
    "xgmodel_final = xgb.XGBClassifier(\n",
    "    subsample=0.5,\n",
    "    n_estimators=181,\n",
    "    learning_rate=0.3,\n",
    "    gamma=2.0,\n",
    "    colsample_bytree=0.5)\n",
    "xgmodel_final.fit(df_all[features], df_all['status_group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on real test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test['status_group'] = clf_final.predict(df_test[features])\n",
    "\n",
    "submission = df_test[['id', 'status_group']].copy()\n",
    "submission.status_group[submission.status_group == 2] = 'non functional'\n",
    "submission.status_group[submission.status_group == 0] = 'functional'\n",
    "submission.status_group[submission.status_group == 1] = 'needs repair'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combination of model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds1 = clf_final.predict_proba(df_test[features])\n",
    "test_preds2 = xgmodel_final.predict_proba(df_test[features])\n",
    "preds_comb_real = pd.DataFrame(0.8 * test_preds1 + 0.2 * test_preds2)\n",
    "preds_comb_real.idxmax(axis=1)\n",
    "\n",
    "df_test['status_group'] = preds_comb_real.idxmax(axis=1).values\n",
    "submission = df_test[['id', 'status_group']].copy()\n",
    "submission.status_group[submission.status_group == 2] = 'non functional'\n",
    "submission.status_group[submission.status_group == 0] = 'functional'\n",
    "submission.status_group[submission.status_group == 1] = 'needs repair'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the id labels in prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-04afca50cc41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'submission' is not defined"
     ]
    }
   ],
   "source": [
    "submission.id = submission.id - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to submission\n",
    "\n",
    "\n",
    "For the final submission I used a pure CLF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7034006b4bd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m submission.to_csv(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/Users/charlotteleysen/Google Drive/*PROJECTS/IE/Term 2/Machine Leaning 2/Tanzania Water Assignment/submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     index=False)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'submission' is not defined"
     ]
    }
   ],
   "source": [
    "submission.to_csv(\n",
    "    path_or_buf='/Users/charlotteleysen/Google Drive/*PROJECTS/IE/Term 2/Machine Leaning 2/Tanzania Water Assignment/submission.csv',\n",
    "    sep=',',\n",
    "    decimal='.',\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
